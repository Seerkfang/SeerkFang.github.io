# jemdoc: menu{MENU}{index.html}, nodate
==Yunhao Fang 方云浩

~~~
{}{img_left}{photos/fyh.jpg}{Yunaho Fang}{160}{160}
Research Scientist Intern,\n
Nvidia\n
Email: seerkfang \[@\] gmail \[DOT\] com\n
[https://twitter.com/home Twitter] \/
[https://github.com/Seerkfang Github] \/ 
[https://www.linkedin.com/in/yunhao-fang-8b318221a/ LinkedIn]
~~~

== About me
I'm a Research Scientist Intern at Nvidia, supervised by Dr. [https://research.nvidia.com/person/yao-lu-jason Jason Lu] and Prof. [https://hanlab.mit.edu/songhan Song Han], and a core contributor to Nvidia’s multimodal model, [https://github.com/NVlabs/VILA VILA].

I hold a Master's degree from the [https://cse.ucsd.edu/ Department of Computer Science and Engineering] at the [https://www.ucsd.edu/ University of California San Diego], where I was fortunate to be advised by Prof. [https://cseweb.ucsd.edu/~haosu/ Hao Su]. Before that, I earned my B.Eng. in Electronic Engineering from [https://www.zju.edu.cn/english/ Zhejiang University]. I have also spent time at [https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/ Shanghai AI Laboratory], as the maintainer of the opensource codebase [https://github.com/open-mmlab/mmtracking mmtracking].

My long-term research goal is to develop automated learning system that integrate closed-loop data pipelines, efficient algorithms, and robust evaluation tools, advancing the frontiers of *multimodal intelligence*.

== Research interests
My research interests include 
- *Perception*
    -- Generalized Representation
    -- Synergy between Understanding and Generation

- *Reasoning and Common Sense*
    -- Concept Emergence and Common Sense
    -- Advanced Reasoning for Scientific Discoveries

- *Generative Modeling*
    -- Efficient World Model
    -- Learning from (Human or AI) Feedback

== Selected Publications & Preprints
Papers sorted by years. The full list is available on [https://scholar.google.com/citations?user=vrYHLMgAAAAJ&hl=en Google Scholar].

=== 2024

~~~
{}{img_left}{figures/fyh/vila^2_teaser.jpg}{vila^2}{240}
*[https://arxiv.org/pdf/2407.17453.pdf VILA^2: VLM Augmented VLM with Self-Improvement]*\n
*Yunhao Fang\**, Ligeng Zhu*, Yao Lu, Yan Wang, Pavlo Molchanov, Jang Hyun Cho, Marco Pavone, Song Han, Hongxu Yin\n
/In Submission/\n
~~~

=== 2023

~~~
{}{img_left}{figures/fyh/verify_cot.jpg}{verify_cot}{240}
*[https://arxiv.org/pdf/2306.03872.pdf Deductive Verification of Chain-of-Thought Reasoning]*\n
Zhan Ling\*, *Yunhao Fang\**, Xuanlin Li, Zhiao Huang, Hao Su\n
/Neural Information Processing Systems *(NeurIPS)* 2023/\n
[https://github.com/lz1oceani/verify_cot \[Code\]]\n
~~~

~~~
{}{img_left}{figures/fyh/vlm_distillation.jpg}{vlm_distillation}{240}
*[https://arxiv.org/pdf/2307.03135 Distilling Large Vision-Language Model with Out-of-Distribution Generalizability]*\n
Xuanlin Li\*, *Yunhao Fang\**, Minghua Liu, Zhan Ling, Zhuowen Tu, Hao Su\n
/International Conference on Computer Vision *(ICCV)* 2023/\n
[https://github.com/xuanlinli17/large_vlm_distillation_ood \[Code\]]\n
~~~

== Professional Services
- *Conference Reviewer*: ECCV 2024, ICLR 2024, CVPR 2024

== Teaching
- Teaching Assistant: CSE 275: Deep Learning for 3D Data at UC San Diego, Fall 2023

== Awards 
- China National Scholarship, 2022
\n

#[publications.html Full list of publications].
#\n
#[cv.pdf A brief cv].
