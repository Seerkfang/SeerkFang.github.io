<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Tongzhou Mu 木同舟</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Tongzhou Mu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="files/CV_TongzhouMu.pdf">CV&nbsp;(Jan&nbsp;2023)</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Tongzhou Mu 木同舟</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photos/tmu.jpg" alt="Tongzhou Mu" width="160px" height="160px" />&nbsp;</td>
<td align="left"><p>Ph.D. candidate,<br />
<a href="https://cse.ucsd.edu/">Department of Computer Science and Engineering</a>,<br />
<a href="https://www.ucsd.edu/">University of California San Diego</a><br />
Email: t3mu [@] eng [DOT] ucsd [DOT] edu<br />
<a href="https://scholar.google.com/citations?user=uVsZydYAAAAJ&amp;hl=en">Google Scholar</a> / 
<a href="https://dblp.org/pid/183/0943.html">DBLP</a> / 
<a href="https://twitter.com/tongzhou_mu">Twitter</a> /
<a href="https://github.com/tongzhoumu">Github</a> / 
<a href="https://www.linkedin.com/in/tongzhou-mu-4ab269ba/">LinkedIn</a></p>
</td></tr></table>
<p><br />
</p>
<h2>About me</h2>
<p>I am a Ph.D. candidate in the <a href="https://cse.ucsd.edu/">Department of Computer Science and Engineering</a> at the <a href="https://www.ucsd.edu/">University of California San Diego</a>, and I am fortunate to be advised by Prof. <a href="https://cseweb.ucsd.edu/~haosu/">Hao Su</a>.
My long-term research goal is to <b>build a decision-making framework with strong generalizability</b>. 
Specifically, I am interested in <b>Reinforcement Learning / Imitation Learning, Concept Discovery and Reasoning, and Robotics / Embodied AI</b>. </p>
<p>Prior to starting as a Ph.D. student, I received my B.Eng. and M.Sc. degrees in computer science from <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>, and <a href="https://www.ucsd.edu/">UC San Diego</a> in 2017 and 2019, respectively.
I have also spent time at 
<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia</a>, 
<a href="https://www.intel.com/content/www/us/en/artificial-intelligence/overview.html">Intel AI</a>, 
<a href="https://research.wormpex.com/">Wormpex AI</a>
, and <a href="https://www.amazon.jobs/en/teams/alexa-ai">Amazon Alexa AI</a>.</p>
<p><b>I am the major contributor of the <a href="https://github.com/haosulab/ManiSkill">ManiSkill benchmark</a></b>, 
and the lead organzier of the <a href="https://sapien.ucsd.edu/challenges/maniskill2021/">ManiSkill Challenge 2021</a> and the <a href="https://ai-workshops.github.io/generalizable-policy-learning-in-the-physical-world/">Generalizable Policy Learning in the Physical World Workshop</a>.</p>
<h2>Research interests</h2>
<p>My research interests include </p>
<ul>
<li><p><b>Reinforcement Learning / Imitation Learning</b></p>
<ul>
<li><p>Sturctured Policies and Neural Programs</p>
</li>
<li><p>Learning from Demonstrations</p>
</li>
<li><p>Curriculum in RL</p>
</li></ul>
</li>
<li><p><b>Concept Discovery</b></p>
<ul>
<li><p>Emerged Concepts from Interactions</p>
</li>
<li><p>Reasoning over Concepts</p>
</li></ul>
</li>
<li><p><b>Robotics / Embodied AI</b></p>
<ul>
<li><p>Planning and Control for Manipulation</p>
</li>
<li><p>Building Tasks in Simulation</p>
</li>
</ul>

</li>
</ul>
<h2>Publications &amp; Preprints</h2>
<p>Papers sorted by years. Representative papers are <span style="background-color:LemonChiffon">highlighted</span>.</p>
<h3>2023</h3>
<table class="imgtable"><tr><td>
<img src="figures/drs.gif" alt="drs" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://sites.google.com/view/icml2023drs">Learning Reusable Dense Rewards for Multi-Stage Tasks</a></b><br />
<b>Tongzhou Mu</b>, Minghua Liu, Hao Su<br />
<i>Submitted to ICML 2023</i><br />
<a href="https://sites.google.com/view/icml2023drs">[Project Page]</a></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/no_pretrain.png" alt="no_pretrain" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/abs/2212.05749">On Pre-Training for Visuo-Motor Control: Revisiting a Learning-from-Scratch Baseline</a></b><br />
Nicklas Hansen*, Zhecheng Yuan*, Yanjie Ze*, <b>Tongzhou Mu* </b>, Aravind Rajeswaran+, Hao Su+, Huazhe Xu+, Xiaolong Wang+<br />
<i>ArXiv preprint, Submitted to ICML 2023</i><br />
<i>Pre-training Robot Learning Workshop at <b>CoRL</b> 2022</i><br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/skill_trans.gif" alt="skill_trans" width="240px" />&nbsp;</td>
<td align="left"><p><span style="background-color:LemonChiffon">
<b><a href="https://arxiv.org/abs/2210.07658">Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization</a></b><br />
Stone Tao, Xiaochen Li, <b>Tongzhou Mu</b>, Zhiao Huang, Yuzhe Qin, Hao Su<br />
<i>ArXiv preprint, Submitted to ICML 2023</i><br />
<i>Deep Rieinforcement Learning Workshop at <b>NeurIPS</b> 2022</i><br />
<a href="https://trajectorytranslation.github.io/">[Project Page]</a>
<a href="https://www.youtube.com/watch?v=M1NA5j6DWHs">[Video]</a><br />
* Stone Tao and Xiaochen Li are undergruduate students I advised</p>
<p></span></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/demo_rl.jpg" alt="demo_rl" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/abs/2303.13489">Boosting Reinforcement Learning and Planning with Demonstrations: A Survey</a></b><br />
<b>Tongzhou Mu</b>, Hao Su<br />
<i>ArXiv preprint</i><br />
<a href="https://drive.google.com/file/d/1F4xvLWPw20tJ010G5IH47-bfrg5TB6PC/view?usp=share_link">[Slides]</a></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/ms2_fancy_teaser.jpg" alt="maniskill2" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/abs/2302.04659">ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills</a></b><br />
Jiayuan Gu, Fanbo Xiang, Xuanlin Li*, Zhan Ling*, Xiqiang Liu*, <b>Tongzhou Mu* </b>, Yihe Tang*, Stone Tao*, Xinyue Wei*, Yunchao Yao*, Xiaodi Yuan, Pengwei Xie, Zhiao Huang, Rui Chen, Hao Su<br />
<i>* equally contributed authors are ordered by alphabets</i><br />
<i>International Conference on Learning Representations <b>(ICLR)</b> 2023</i><br />
<a href="https://github.com/haosulab/ManiSkill2">[Code]</a>
<a href="https://maniskill2.github.io/">[Project Page]</a>
<a href="https://sapien.ucsd.edu/challenges/maniskill2022/">[Challenge Website]</a></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/active.jpg" alt="active" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/abs/2201.11924">Close the Optical Sensing Domain Gap by Physics-Grounded Active Stereo Sensor Simulation</a></b><br />
Xiaoshuai Zhang, Rui Chen, Fanbo Xiang, Yuzhe Qin, Jiayuan Gu, Zhan Ling, Minghua Liu, Peiyu Zeng, Songfang Han, Zhiao Huang, <b>Tongzhou Mu</b>, Jing Xu, Hao Su<br />
<i>IEEE Transactions on Robotics <b>(T-RO)</b> 2023</i><br /></p>
</td></tr></table>
<h3>2022</h3>
<table class="imgtable"><tr><td>
<img src="figures/inter_rl.jpg" alt="inter_rl" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/abs/2201.08520">Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning</a></b><br />
<b>Tongzhou Mu</b>, Kaixiang Lin, Feiyang Niu, Govind Thattai<br />
<i>Transactions on Machine Learning Research <b>(TMLR)</b> 2022</i><br />
<i>Elements of Reasoning: Objects, Structure, and Causality Workshop at <b>ICLR</b> 2022</i><br /></p>
</td></tr></table>
<h3>2021</h3>
<table class="imgtable"><tr><td>
<img src="figures/ms1.gif" alt="ManiSkill" width="240px" />&nbsp;</td>
<td align="left"><p><span style="background-color:LemonChiffon">
<b><a href="https://arxiv.org/abs/2107.14483">ManiSkill: Generalizable Manipulation Skill Benchmark with Large-Scale Demonstrations</a></b><br />
<b>Tongzhou Mu* </b>, Zhan Ling*, Fanbo Xiang*, Derek Yang*, Xuanlin Li*, Stone Tao, Zhiao Huang, Zhiwei Jia, Hao Su<br />
<i>Conference on Neural Information Processing Systems <b>(NeurIPS)</b> Datasets and Benchmarks Track 2021</i><br />
<a href="https://drive.google.com/file/d/127NOQigxP7bTZ8USxBJd_eOKxNeju4em/view?usp=sharing">[Video]</a>
<a href="https://drive.google.com/file/d/10CWlGUbtFXPek0p3HRpYdnVZM1asi0wO/view?usp=sharing">[Slides]</a>
<a href="https://drive.google.com/file/d/1aY6C6smsA6B02JCVEWB_mV58VlaUpum0/view?usp=sharing">[Poster]</a>
<a href="https://github.com/haosulab/ManiSkill">[Code]</a>
<a href="https://github.com/haosulab/ManiSkill-Learn">[Baselines]</a>
<a href="https://sapien.ucsd.edu/challenges/maniskill2021/">[Challenge Website]</a></p>
<p></span></p>
</td></tr></table>
<h3>2020</h3>
<table class="imgtable"><tr><td>
<img src="figures/policy_refactorization.jpg" alt="policy_refactorization" width="240px" />&nbsp;</td>
<td align="left"><p><span style="background-color:LemonChiffon">
<b><a href="https://arxiv.org/abs/2011.00971">Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals</a></b><br />
<b>Tongzhou Mu* </b>, Jiayuan Gu*, Zhiwei Jia, Hao Tang, Hao Su<br />
<i>Conference on Neural Information Processing Systems <b>(NeurIPS)</b> 2020</i><br />
<a href="https://jiayuan-gu.github.io/policy-refactorization">[Project Page]</a>
<a href="https://jiayuan-gu.github.io/policy-refactorization/files/poster_policy_refactorization.pdf">[Poster]</a>
<a href="https://jiayuan-gu.github.io/policy-refactorization/files/slides_policy_refactorization.pdf">[Slides]</a>
<a href="https://github.com/Jiayuan-Gu/policy-refactorization">[Code]</a><br /></p>
<p></span></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/sail.jpg" alt="sail" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/abs/1911.10947">State Alignment-based Imitation Learning</a></b><br />
Fangchen Liu, Zhan Ling, <b>Tongzhou Mu</b>, Hao Su<br />
<i>International Conference on Learning Representations <b>(ICLR)</b> 2020</i><br /></p>
</td></tr></table>
<p><br /></p>
<h3>Before 2019</h3>
<table class="imgtable"><tr><td>
<img src="figures/value_transfer.jpg" alt="value_transfer" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://drive.google.com/file/d/0B_utB5Y8Y6D5T3FGRF9Ic3RQU1NYNmV4N2hGckRiTmVJRFhv/view">Transfer Value or Policy? A Value-centric Framework Towards Transferrable Continuous Reinforcement Learning</a></b><br />
Xingchao Liu*, <b>Tongzhou Mu* </b>, Hao Su<br />
<i>Deep Reinforcement Learning Workshop at <b>NeurIPS</b> 2018</i><br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/doubly_sgd.jpg" alt="doubly_sgd" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://www.ijcai.org/Proceedings/2017/0378.pdf">Accelerated Doubly Stochastic Gradient Algorithm for Large-scale Empirical Risk Minimization</a></b><br />
Zebang Shen, Hui Qian, <b>Tongzhou Mu</b>, and Chao Zhang<br />
<i>International Joint Conference on Artificial Intelligence <b>(IJCAI)</b> 2017</i><br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/adaptive_vr.jpg" alt="adaptive_vr" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://www.ijcai.org/Proceedings/16/Papers/284.pdf">Adaptive Variance Reducing for Stochastic Gradient Descent</a></b><br />
Zebang Shen, Hui Qian, Tengfei Zhou, and <b>Tongzhou Mu</b><br />
<i>International Joint Conference on Artificial Intelligence <b>(IJCAI)</b> 2016</i><br /></p>
</td></tr></table>
<h2>Talks</h2>
<ul>
<li><p><a href="https://drive.google.com/file/d/1F4xvLWPw20tJ010G5IH47-bfrg5TB6PC/view?usp=share_link"><b>Boosting Reinforcement Learning and Planning with Demonstrations</b></a><br />
<i>Ph.D. Research Exam at UC San Diego</i>, Jan 2023<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://drive.google.com/file/d/1lR-TrXGHdO9zgzf8Y8ESRpXSM_KtefGb/view?usp=share_link"><b>On Pre-Training for Visuo-Motor Control: Revisiting a Learning-from-Scratch Baseline</b></a><br />
<i>Pre-training Robot Learning Workshop at CoRL 2022</i>, Dec 2022<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://drive.google.com/file/d/1ls37WFQ2Y0aitBYNLir5SjlJM-Euy6Rh/view?usp=sharing"><b>Generalizable Manipulation Skill Benchmark with Large-Scale Demonstrations</b></a><br />
<i>UC Berkeley Robot Learning Lab</i>, &nbsp;&nbsp;&nbsp;Nov 2021<br />
<i>Stanford Vision and Learning Lab</i>, &nbsp;Dec 2021</p>
</li>
</ul>
<ul>
<li><p><a href="https://youtu.be/HJfC22D4a7M?t=237"><b>Task-driven Entity Abstraction from Visual Observations</b></a><br />
<i>Qualcomm AI Lab</i>, Mar 2020</p>
</li>
</ul>
<h2>Professional Services</h2>
<ul>
<li><p><b>Workshop Organizer</b>: <a href="https://ai-workshops.github.io/generalizable-policy-learning-in-the-physical-world/">ICLR 2022 Workshop &ldquo;Generalizable Policy Learning in the Physical World&rdquo;</a> (<b>Lead Organzier</b>)</p>
</li>
<li><p><b>Tutorial Organizer</b>: <a href="https://ai-workshops.github.io/building-and-working-in-environments-for-embodied-ai-cvpr-2022/">CVPR 2022 Tutorial &ldquo;Building and Working in Environments for Embodied AI&rdquo;</a></p>
</li>
<li><p><b>Challenge Organizer</b>: </p>
<ul>
<li><p><a href="https://sapien.ucsd.edu/challenges/maniskill/2021/">SAPIEN ManiSkill Challenge 2021</a> (<b>Lead Organzier</b>)</p>
</li>
<li><p><a href="https://sapien.ucsd.edu/challenges/maniskill/2022/">SAPIEN ManiSkill Challenge 2022</a></p>
</li></ul>
</li>
<li><p><b>Conference Reviewer</b>: ICLR, NeurIPS, ICRA, IROS, ICCV, AAAI</p>
</li>
<li><p><b>Journal Reviewer</b>: RA-L</p>
</li>
</ul>
<h2>Teaching</h2>
<ul>
<li><p><b>Consultant Volunteer</b>: CSE291-J00 Deep Learning Lab (Computer Vision) at UC San Diego, Fall 2020</p>
</li>
<li><p><b>Teaching Assistant</b>: CSE 152 Introduction to Computer Vision at UC San Diego, Fall 2018</p>
</li>
</ul>
<h2>Awards </h2>
<ul>
<li><p><a href="https://icpc.global/regionals/results">ACM-ICPC (International Collegiate Programming Contest)</a> Asia Regional Contest <b>Gold Medal</b>, 2015</p>
</li>
<li><p><a href="https://www.ccf.org.cn/c/2019-06-11/663599.shtml#:~:text=The%20award%20is%20for%20100,social%20activities%20and%20commonweal%20activities">China Computer Federation Elite Collegiate Award</a> (top 108 in China), 2016</p>
</li>
<li><p>Award of Excellence for Stars of Tomorrow Internship Program, Microsoft Research Asia, 2017
<br /></p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
