<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Tongzhou Mu 木同舟</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Tongzhou Mu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="files/Resume_TongzhouMu.pdf">Résumé&nbsp;(Nov&nbsp;2020)</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Tongzhou Mu 木同舟</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photos/tmu.jpg" alt="Tongzhou Mu" width="160px" height="160px" />&nbsp;</td>
<td align="left"><p>Ph.D. student,<br />
<a href="https://cse.ucsd.edu/">Department of Computer Science and Engineering</a>,<br />
<a href="https://www.ucsd.edu/">University of California San Diego</a><br />
Email: t3mu [@] eng [DOT] ucsd [DOT] edu<br />
<a href="https://scholar.google.com/citations?user=uVsZydYAAAAJ&amp;hl=en">Google Scholar</a> / <a href="https://dblp.org/pid/183/0943.html">DBLP</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I am a Ph.D. student in the <a href="https://cse.ucsd.edu/">Department of Computer Science and Engineering</a> at the <a href="https://www.ucsd.edu/">University of California San Diego</a>, and I am fortunate to be advised by Prof. <a href="https://cseweb.ucsd.edu/~haosu/">Hao Su</a>.
My research interests are broadly in reinforcement learning and concept discovery. </p>
<p>Prior to starting as a Ph.D. student, I received my B.Eng. and M.Sc. degrees in computer science from <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>, and <a href="https://www.ucsd.edu/">UC San Diego</a> in 2017 and 2019, respectively.
I have also spent time at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia</a>, <a href="https://www.intel.com/content/www/us/en/artificial-intelligence/overview.html">Intel AI</a> and <a href="https://research.wormpex.com/">Wormpex AI</a>.</p>
<h2>Research interests</h2>
<p>My research interests include </p>
<ul>
<li><p>Reinforcement Learning</p>
<ul>
<li><p>Object-centric RL</p>
</li>
<li><p>Model-based RL</p>
</li>
<li><p>Curriculum in RL</p>
</li></ul>
</li>
<li><p>Concept Discovery</p>
<ul>
<li><p>Emergent Concepts in Task Completion</p>
</li>
<li><p>Reasoning over Concepts</p>
</li>
</ul>

</li>
</ul>
<h2>Preprints</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2107.14483">ManiSkill: Learning-from-Demonstrations Benchmark for Generalizable Manipulation Skills</a><br />
<b>Tongzhou Mu* </b>, Zhan Ling*, Fanbo Xiang*, Derek Yang*, Xuanlin Li*, Stone Tao, Zhiao Huang, Zhiwei Jia, Hao Su<br />
<i>arXiv Preprint 2021</i><br />
<a href="https://github.com/haosulab/ManiSkill">[Code]</a>
<a href="https://sapien.ucsd.edu/challenges/maniskill2021/">[Challenge Website]</a></p>
</li>
</ul>
<h2>Publications </h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2011.00971">Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals</a><br />
<b>Tongzhou Mu* </b>, Jiayuan Gu*, Zhiwei Jia, Hao Tang, Hao Su<br />
<i>Conference on Neural Information Processing Systems (NeurIPS) 2020</i><br />
<a href="https://jiayuan-gu.github.io/policy-refactorization">[Project Page]</a>
<a href="https://jiayuan-gu.github.io/policy-refactorization/files/poster_policy_refactorization.pdf">[Poster]</a>
<a href="https://github.com/Jiayuan-Gu/policy-refactorization">[Code]</a><br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1911.10947">State Alignment-based Imitation Learning</a><br />
Fangchen Liu, Zhan Ling, <b>Tongzhou Mu</b>, Hao Su<br />
<i>International Conference on Learning Representations (ICLR) 2020</i><br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://drive.google.com/file/d/0B_utB5Y8Y6D5T3FGRF9Ic3RQU1NYNmV4N2hGckRiTmVJRFhv/view">Transfer Value or Policy? A Value-centric Framework Towards Transferrable Continuous Reinforcement Learning</a><br />
Xingchao Liu*, <b>Tongzhou Mu* </b>, Hao Su<br />
<i>Deep Reinforcement Learning Workshop at NeurIPS 2018</i><br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://www.ijcai.org/Proceedings/2017/0378.pdf">Accelerated Doubly Stochastic Gradient Algorithm for Large-scale Empirical Risk Minimization</a><br />
Zebang Shen, Hui Qian, <b>Tongzhou Mu</b>, and Chao Zhang<br />
<i>International Joint Conference on Artificial Intelligence (IJCAI) 2017</i><br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://www.ijcai.org/Proceedings/16/Papers/284.pdf">Adaptive Variance Reducing for Stochastic Gradient Descent</a><br />
Zebang Shen, Hui Qian, Tengfei Zhou, <b>Tongzhou Mu</b><br />
<i>International Joint Conference on Artificial Intelligence (IJCAI) 2016</i><br /></p>
</li>
</ul>
<h2>Awards </h2>
<ul>
<li><p><a href="https://icpc.global/regionals/results">ACM-ICPC (International Collegiate Programming Contest)</a> Asia Regional Contest <b>Gold Medal</b>, 2015</p>
</li>
<li><p><a href="https://www.ccf.org.cn/c/2019-06-11/663599.shtml">China Computer Federation Elite Collegiate Award</a> (top 108 in China), 2016</p>
</li>
<li><p>Award of Excellence for Stars of Tomorrow Internship Program, Microsoft Research Asia, 2017
<br /></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2021-08-03 14:52:28 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
