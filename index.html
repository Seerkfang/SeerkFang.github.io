<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yunhao Fang 方云浩</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yunhao Fang</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="files/CV_YunhaoFang.pdf">CV&nbsp;(Dec&nbsp;2023)</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Yunhao Fang 方云浩</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photos/fyh.jpg" alt="Yunaho Fang" width="160px" height="160px" />&nbsp;</td>
<td align="left"><p>Research Scientist Intern,<br />
Nvidia
Email: seerkfang [@] gmail [DOT] com<br />
<a href="https://twitter.com/home">Twitter</a> /
<a href="https://github.com/Seerkfang">Github</a> / 
<a href="https://www.linkedin.com/in/yunhao-fang-8b318221a/">LinkedIn</a></p>
</td></tr></table>
<p><br /></p>
<p><font color=red size=+0.5>I am seeking a <b>Ph.D. position for fall 2025</b> or a <b>full-time employment</b> opportunity. Please feel free to contact me!</font></p>
<p><font color=red size=+0.5>I am currently working on <b>large language model</b> and <b>vision language model</b> for decision making agents. Email me if you are interested in collaboration!</font></p>
<h2>About me</h2>
<p>I got my Master degree in the <a href="https://cse.ucsd.edu/">Department of Computer Science and Engineering</a> at the <a href="https://www.ucsd.edu/">University of California San Diego</a>, and I am fortunate to be advised by Prof. <a href="https://cseweb.ucsd.edu/~haosu/">Hao Su</a>.</p>
<p>Prior to starting as a Master student, I received my B.Eng. in Electronic Engineering from <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>.
I have also spent time at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Shanghai AI Laboratory</a>, as the maintainer of the opensource codebase <a href="https://github.com/open-mmlab/mmtracking">mmtracking</a>.</p>
<p>My long-term research goal is to build a automatic learning system with generalizable perception and beyond-human level decision making capabilities.</p>
<h2>Research interests</h2>
<p>My research interests include </p>
<ul>
<li><p><b>Perception</b></p>
<ul>
<li><p>Senergy of Vision Language Models</p>
</li>
<li><p>Generalizable Representation for Multimodal Signals</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b>Reasoning and Common Sense</b></p>
<ul>
<li><p>Concept Emergence and Common Sense</p>
</li>
<li><p>Reasoning over Common Sense and Formal Systems (Verification)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b>Embodied AI</b></p>
<ul>
<li><p>General Sequence Modeling</p>
</li>
<li><p>Efficient Learning from (Human or AI) Feedback</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b>Artificial General Intelligence</b></p>
<ul>
<li><p>General Decision Making</p>
</li>
<li><p>Creative Agents</p>
</li>
</ul>

</li>
</ul>
<h2>Publications &amp; Preprints</h2>
<p>Papers sorted by years. Representative papers are <span style="background-color:LemonChiffon">highlighted</span>.</p>
<h3>2023</h3>
<table class="imgtable"><tr><td>
<img src="figures/fyh/hierarchical_exploration.jpg" alt="hierarchical_exploration" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/pdf/2311.00694.pdf">Unleashing the Creative Mind: Language Model as Hierarchical Policy For Improved Exploration on Challenging Problem Solving</a></b><br />
Zhan Ling, <b>Yunhao Fang</b>, Xuanlin Li, Tongzhou Mu, Mingu Lee, Mingu Lee, Reza Pourreza, Roland Memisevic, Hao Su<br />
<i>In Submission</i><br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/fyh/verify_cot.jpg" alt="verify_cot" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/pdf/2306.03872.pdf">Deductive Verification of Chain-of-Thought Reasoning</a></b><br />
Zhan Ling*, <b>Yunhao Fang*</b>, Xuanlin Li, Zhiao Huang, Hao Su<br />
<i>Neural Information Processing Systems <b>(NeurIPS)</b> 2023</i><br />
<a href="https://github.com/lz1oceani/verify_cot">[Code]</a><br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="figures/fyh/vlm_distillation.jpg" alt="vlm_distillation" width="240px" />&nbsp;</td>
<td align="left"><p><b><a href="https://arxiv.org/pdf/2307.03135">Distilling Large Vision-Language Model with Out-of-Distribution Generalizability</a></b><br />
Xuanlin Li*, <b>Yunhao Fang*</b>, Minghua Liu, Zhan Ling, Zhuowen Tu, Hao Su<br />
<i>International Conference on Computer Vision <b>(ICCV)</b> 2023</i><br />
<a href="https://github.com/xuanlinli17/large_vlm_distillation_ood">[Code]</a><br /></p>
</td></tr></table>
<h2>Awards </h2>
<ul>
<li><p>China National Scholarship, 2022
<br /></p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
